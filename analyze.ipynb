{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "parent_dir = os.path.dirname(os.path.dirname(os.path.abspath('.')))\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class Analyzer:\n",
    "    \n",
    "    def __init__(self, network):\n",
    "        self.network = network\n",
    "        \n",
    "    def get_degree_distribution(self):\n",
    "        \"Returns the plot of the degree distribution with a log-log scale\"\n",
    "        \n",
    "        N = self.network.number_of_nodes()\n",
    "        degrees = [self.network.in_degree(n) for n in self.network.nodes()] if self.network.is_directed() else [self.network.degree(n) for n in self.network.nodes()]\n",
    "        \n",
    "        N_k = {}\n",
    "        for k in degrees:\n",
    "            if k not in N_k:\n",
    "                N_k[k] = 1\n",
    "            else:\n",
    "                N_k[k] += 1\n",
    "                \n",
    "        p_k = {}\n",
    "        for k in N_k:\n",
    "            p_k[k] = N_k[k] / N\n",
    "        \n",
    "        # Plotting in log-log scale\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.loglog(list(p_k.keys()), list(p_k.values()), marker='o', linestyle='None', color='b')\n",
    "        plt.title('Log-log Degree Distribution')\n",
    "        plt.xlabel('Degree')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.grid(True)\n",
    "\n",
    "        return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks_gen import randomG\n",
    "import random\n",
    "\n",
    "n = 25000\n",
    "\n",
    "# take p randomly between 1/24999 and 1\n",
    "p = random.uniform(1/(n-1), 0.01)\n",
    "\n",
    "g1 = randomG(n, p)\n",
    "analyzer_g1 = Analyzer(g1)\n",
    "plt = analyzer_g1.get_degree_distribution()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(g1.edges()))\n",
    "print(len(g1.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the graph\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the graph\n",
    "print(stream_diam(g1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "degree_distribution = [d for _, d in G.degree()]\n",
    "\n",
    "min = np.min(degree_distribution)\n",
    "max = np.max(degree_distribution)\n",
    "\n",
    "# normalize the degree distribution beteen 0 and max - min\n",
    "normalized_degree_distribution = [d - min for d in degree_distribution]\n",
    "\n",
    "if np.sum(normalized_degree_distribution) % 2 != 0:\n",
    "    normalized_degree_distribution[0] += 1\n",
    "\n",
    "# Generate the small graph\n",
    "small_graph = nx.configuration_model(normalized_degree_distribution[:3000])\n",
    "\n",
    "# Compute the degree distribution of the small graph\n",
    "analyzer_g2 = Analyzer(small_graph)\n",
    "plt = analyzer_g2.get_degree_distribution()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(small_graph, with_labels=False, linewidths=0.01, node_size=1, width=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preferential Attachment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks_gen import preferentialG\n",
    "import random\n",
    "\n",
    "# generate a preferential graph for n = 25000 and different values of p (between 0 excluded and 1 included) and plot the degree distribution for each graph\n",
    "n = 25000\n",
    "\n",
    "ps = [0.01, 0.1, 0.5, 0.7, 1]\n",
    "\n",
    "# take p randomly between 1/24999 and 1\n",
    "for p in ps:\n",
    "    g2 = preferentialG(n, p)\n",
    "    analyzer_g2 = Analyzer(g2)\n",
    "    print(len(g2.edges()))\n",
    "    plt = analyzer_g2.get_degree_distribution()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized Watts-Strogatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from networks_gen import GenWS2DG\n",
    "\n",
    "# degree_distribution = [d for _, d in G.degree()]\n",
    "\n",
    "# min = np.min(degree_distribution)\n",
    "# max = np.max(degree_distribution)\n",
    "\n",
    "# # normalize the degree distribution beteen 0 and max - min\n",
    "# normalized_degree_distribution = [d - min for d in degree_distribution]\n",
    "\n",
    "# normalized_degree_distribution = normalized_degree_distribution[:3000]\n",
    "\n",
    "# if np.sum(normalized_degree_distribution) % 2 != 0:\n",
    "#     normalized_degree_distribution[-1] += 1\n",
    "\n",
    "# Generate the small graph\n",
    "small_graph = GenWS2DG(2500, 1, 1000, 1)\n",
    "\n",
    "# Compute the degree distribution of the small graph\n",
    "analyzer_g2 = Analyzer(small_graph)\n",
    "plt = analyzer_g2.get_degree_distribution()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affiliation Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = nx.read_edgelist('net_2', nodetype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n = len(G.nodes())\n",
    "m = 4\n",
    "learning_rate = 0.01\n",
    "epsilon = 1e-8  \n",
    "max_iter = 100\n",
    "gradient = np.inf \n",
    "\n",
    "F = np.random.rand(n, m)\n",
    "sum_v = np.sum(F, axis=0)\n",
    "\n",
    "def log_likelihood(u, F, G, sum_v):\n",
    "    sum_1 = 0\n",
    "    for v in G.neighbors(u):\n",
    "        dot_product = np.dot(F[u], np.transpose(F[v]))\n",
    "        sum_1 += np.sum((F[v] * np.exp(-dot_product) / (1 - np.exp(-dot_product)) + epsilon))\n",
    "    \n",
    "    sum_2 = sum_v - F[u] - np.sum(F[list(G.neighbors(u))], axis=0)\n",
    "    return sum_1 - sum_2\n",
    "\n",
    "while max_iter > 0 and gradient > np.zeros((n, m)).all():\n",
    "    print(\"Iteration: \", max_iter)\n",
    "    for row in range(n):\n",
    "        gradient = np.gradient(log_likelihood(row, F, G, sum_v))\n",
    "        F[row] = F[row] + learning_rate * gradient\n",
    "        F[row] = np.maximum(F[row], 0)\n",
    "    max_iter -= 1\n",
    "    \n",
    "# normalize F between 0 and 1\n",
    "F = F / np.max(F)\n",
    "    \n",
    "print(F)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
